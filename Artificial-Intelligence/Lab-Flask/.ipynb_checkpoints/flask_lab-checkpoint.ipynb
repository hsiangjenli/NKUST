{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f890c78a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flask-ngrok\n",
      "  Using cached flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from flask-ngrok) (2.26.0)\n",
      "Collecting Flask>=0.8\n",
      "  Using cached Flask-2.0.2-py3-none-any.whl (95 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Using cached Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Requirement already satisfied: click>=7.1.2 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (8.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from Flask>=0.8->flask-ngrok) (3.0.1)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from click>=7.1.2->Flask>=0.8->flask-ngrok) (4.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from click>=7.1.2->Flask>=0.8->flask-ngrok) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.0.1)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from Werkzeug>=2.0->Flask>=0.8->flask-ngrok) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-metadata->click>=7.1.2->Flask>=0.8->flask-ngrok) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-metadata->click>=7.1.2->Flask>=0.8->flask-ngrok) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->flask-ngrok) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->flask-ngrok) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->flask-ngrok) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\roger\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->flask-ngrok) (3.3)\n",
      "Installing collected packages: Werkzeug, itsdangerous, Flask, flask-ngrok\n",
      "Successfully installed Flask-2.0.2 Werkzeug-2.0.2 flask-ngrok-0.0.25 itsdangerous-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install flask-ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59496d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6586572f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Roger\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "import numpy as np\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c473b53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Classifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Value, Variety and Viability: Designing For Co...</td>\n",
       "      <td>While service-dominant logic proposes that all...</td>\n",
       "      <td>THEORETICAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3D U-Net: Learning Dense Volumetric Segmentati...</td>\n",
       "      <td>This paper introduces a network for volumetric...</td>\n",
       "      <td>ENGINEERING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "5  Value, Variety and Viability: Designing For Co...   \n",
       "6  3D U-Net: Learning Dense Volumetric Segmentati...   \n",
       "\n",
       "                                            Abstract Classifications  \n",
       "5  While service-dominant logic proposes that all...     THEORETICAL  \n",
       "6  This paper introduces a network for volumetric...     ENGINEERING  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('dataset.csv')\n",
    "data[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5502b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word2idx.json', 'r') as f:\n",
    "    word2idx = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9434416b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx.get(\"<pad>\" , word2idx[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfbe160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet(nn.Module):\n",
    "    def __init__(self,vocab_num, vocabulary_size):\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.hidden_dim = 512\n",
    "        self.embedding = nn.Embedding(vocab_num,vocabulary_size,padding_idx=0) \n",
    "        self.sent_rnn = nn.GRU(vocabulary_size,\n",
    "                                self.hidden_dim,\n",
    "                                bidirectional=True,\n",
    "                                batch_first=True)\n",
    "        self.l1 = nn.Linear(self.hidden_dim, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        b,s,w,e = x.shape\n",
    "        x = x.view(b,s*w,e)\n",
    "        x, __ = self.sent_rnn(x)\n",
    "        x = x.view(b,s,w,-1)\n",
    "        x = torch.max(x,dim=2)[0]\n",
    "        x = x[:,:,:self.hidden_dim] + x[:,:,self.hidden_dim:]\n",
    "        x = torch.max(x,dim=1)[0]\n",
    "        x = torch.sigmoid(self.l1(F.relu(x)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edf95714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simpleNet(\n",
       "  (embedding): Embedding(40169, 300, padding_idx=0)\n",
       "  (sent_rnn): GRU(300, 512, batch_first=True, bidirectional=True)\n",
       "  (l1): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = simpleNet(len(word2idx),300)\n",
    "model.load_state_dict(torch.load('model_final.pkl',\n",
    "                                 map_location=torch.device('cpu')))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eaff68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def sentence_to_indices(sentence, word_dict):\n",
    "  return [word_dict.get(word, word_dict[\"<unk>\"]) for word in word_tokenize(sentence) ]\n",
    "\n",
    "def preprocess_sample(text, word_dict , max_len = 500):\n",
    "  processed = [sentence_to_indices(sent, word_dict) for sent in text.split('$$$')]\n",
    "  max_len = max([min(len(sentence), max_len) for sentence in processed])\n",
    "  pad_abstract = []\n",
    "  for sentence in processed:\n",
    "    if len(sentence) > max_len:\n",
    "      pad_abstract.append(sentence[:max_len])\n",
    "    else:\n",
    "      pad_abstract.append(sentence+[word_dict['<pad>']]*(max_len-len(sentence)))\n",
    "  return pad_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adf7ba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this paper, we present a detailed design of dynamic video segmentation network (DVSNet) for fast and efficient semantic video segmentation.$$$DVSNet consists of two convolutional neural networks: a segmentation network and a flow network.$$$The former generates highly accurate semantic segmentations, but is deeper and slower.$$$The latter is much faster than the former, but its output requires further processing to generate less accurate semantic segmentations.$$$We explore the use of a decision network to adaptively assign different frame regions to different networks based on a metric called expected confidence score.$$$Frame regions with a higher expected confidence score traverse the flow network.$$$Frame regions with a lower expected confidence score have to pass through the segmentation network.$$$We have extensively performed experiments on various configurations of DVSNet, and investigated a number of variants for the proposed decision network.$$$The experimental results show that our DVSNet is able to achieve up to 70.4% mIoU at 19.8 fps on the Cityscape dataset.$$$A high speed version of DVSNet is able to deliver an fps of 30.4 with 63.2% mIoU on the same dataset.$$$DVSNet is also able to reduce up to 95% of the computational workloads.\n",
      "Predition : THEORETICAL \n",
      "Anwser : ENGINEERING\n"
     ]
    }
   ],
   "source": [
    "idx = 12\n",
    "def Testing(idx):\n",
    "  print(data['Abstract'][idx])\n",
    "  sent_p = preprocess_sample(data['Abstract'][idx],word2idx)\n",
    "  input = torch.LongTensor([sent_p])\n",
    "  output = model(input).squeeze(0)\n",
    "  label = ['THEORETICAL', 'ENGINEERING', 'EMPIRICAL', 'OTHERS']\n",
    "  print('Predition :',end = ' ')\n",
    "  for i,cls in enumerate(output):\n",
    "    if cls > 0.5:\n",
    "      print(label[i],end = ' ')\n",
    "  print('')\n",
    "  print('Anwser :',data['Classifications'][idx])\n",
    "\n",
    "Testing(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184a7af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We consider the transmission of packets across a lossy end-to-end network path so as to achieve low in-order delivery delay.$$$This can be formulated as a decision problem, namely deciding whether the next packet to send should be an information packet or a coded packet.$$$Importantly, this decision is made based on delayed feedback from the receiver.$$$While an exact solution to this decision problem is challenging, we exploit ideas from queueing theory to derive scheduling policies based on prediction of a receiver queue length that, while suboptimal, can be efficiently implemented and offer substantially better performance than state of the art approaches.$$$We obtain a number of useful analytic bounds that help characterise design trade-offs and our analysis highlights that the use of prediction plays a key role in achieving good performance in the presence of significant feedback delay.$$$Our approach readily generalises to networks of paths and we illustrate this by application to multipath transport scheduler design.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Abstract'][99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8676f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(text):\n",
    "  sent_p = preprocess_sample(text,word2idx)\n",
    "  input = torch.LongTensor([sent_p])\n",
    "  output = model(input).squeeze(0)\n",
    "  label = ['THEORETICAL', 'ENGINEERING', 'EMPIRICAL', 'OTHERS']\n",
    "  anwser = []\n",
    "  for i,cls in enumerate(output):\n",
    "    if cls > 0.5:\n",
    "      anwser.append(label[i])\n",
    "  print(anwser)\n",
    "  return anwser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ca8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Running on http://0d47-140-127-114-22.ngrok.io\n",
      " * Traffic stats available on http://127.0.0.1:4040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Dec/2021 15:30:29] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:30:29] \"GET /static/css/nicepage.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:30:29] \"GET /static/css/Page-1.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:30:29] \"GET /static/css/bootstrap/bootstrap.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:30:29] \"GET /static/images/61642b43-817b-ae1b-79ed-23f3c98bee6c.jpeg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:30:29] \"GET /static/images/banner-bg.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:30:31] \"GET /static/images/images-removebg-preview.ico HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:37:41] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:37:41] \"GET /static/css/nicepage.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:37:41] \"GET /static/css/Page-1.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:37:41] \"GET /static/css/bootstrap/bootstrap.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:37:41] \"GET /static/images/61642b43-817b-ae1b-79ed-23f3c98bee6c.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:37:41] \"GET /static/images/banner-bg.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:41:26] \"POST /submit HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:41:26] \"GET /static/css/nicepage.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:41:26] \"GET /static/css/Page-1.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:41:26] \"GET /static/css/bootstrap/bootstrap.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:41:26] \"GET /static/images/61642b43-817b-ae1b-79ed-23f3c98bee6c.jpeg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [07/Dec/2021 15:41:26] \"GET /static/images/banner-bg.png HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['THEORETICAL']\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask\n",
    "from flask_ngrok import run_with_ngrok\n",
    "from flask import request, url_for, redirect, flash,render_template\n",
    "\n",
    "TEMPLATE = 'templates'\n",
    "STATIC = 'static'\n",
    "\n",
    "app = Flask(__name__,template_folder=TEMPLATE,static_folder=STATIC)\n",
    "run_with_ngrok(app)\n",
    "\n",
    "input_text = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e1cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
